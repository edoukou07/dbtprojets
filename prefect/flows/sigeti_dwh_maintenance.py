"""
SIGETI DWH - Maintenance Mensuelle (PRIORIT√â 3)
================================================

Flow Prefect pour la maintenance lourde mensuelle.

‚ö†Ô∏è  EX√âCUTION: 1er de chaque mois √† 3h du matin
üéØ Objectif: Maintenance lourde pour optimiser performances

√âtapes:
1. VACUUM FULL sur les anciennes partitions (> 3 mois)
2. Archiver les partitions tr√®s anciennes (> 5 ans)
3. R√©organiser les index
4. G√©n√©rer rapport de sant√©

Performance attendue:
- R√©cup√©ration espace disque: 10-30%
- Optimisation index: 20-50% plus rapides
- Dur√©e: 30-60 minutes
"""

import subprocess
from pathlib import Path
from datetime import datetime, timedelta
from prefect import flow, task
from prefect.logging import get_run_logger

# Configuration
PROJECT_ROOT = Path(__file__).parent.parent.parent
DB_CONFIG = {
    "host": "localhost",
    "port": "5432",
    "dbname": "sigeti_node_db",
    "user": "postgres",
    "password": "postgres"
}


def execute_sql(sql_query: str, description: str = ""):
    """Ex√©cuter une requ√™te SQL et retourner le r√©sultat."""
    logger = get_run_logger()
    
    if description:
        logger.info(f"üîß {description}")
    
    env = {
        "PGPASSWORD": DB_CONFIG["password"],
        "PGCLIENTENCODING": "UTF8"
    }
    
    cmd = [
        "psql",
        "-h", DB_CONFIG["host"],
        "-p", DB_CONFIG["port"],
        "-U", DB_CONFIG["user"],
        "-d", DB_CONFIG["dbname"],
        "-c", sql_query
    ]
    
    try:
        result = subprocess.run(
            cmd,
            env={**subprocess.os.environ.copy(), **env},
            capture_output=True,
            text=True,
            encoding='utf-8',
            errors='replace',
            timeout=3600  # 1h max
        )
        
        if result.returncode == 0:
            return result.stdout
        else:
            logger.error(f"‚ùå Erreur: {result.stderr}")
            raise RuntimeError(result.stderr)
            
    except subprocess.TimeoutExpired:
        logger.error("‚ùå Timeout apr√®s 1h")
        raise


@task(name="vacuum_old_partitions", retries=0)
def vacuum_old_partitions():
    """VACUUM FULL sur les partitions de plus de 3 mois."""
    logger = get_run_logger()
    logger.info("üßπ VACUUM FULL des anciennes partitions...")
    
    # Calculer l'ann√©e de la limite (3 mois en arri√®re)
    cutoff_date = datetime.now() - timedelta(days=90)
    cutoff_year = cutoff_date.year
    
    logger.info(f"üìÖ Ann√©e limite: {cutoff_year}")
    
    # Lister les partitions √† vacuum
    partitions_query = f"""
    SELECT tablename 
    FROM pg_tables 
    WHERE schemaname = 'dwh_facts' 
      AND tablename LIKE 'fait_attributions_20%'
      AND tablename <= 'fait_attributions_{cutoff_year}'
    ORDER BY tablename;
    """
    
    partitions_output = execute_sql(partitions_query, "Liste des partitions √† vacuum")
    partitions = [p.strip() for p in partitions_output.split('\n') if p.strip() and not p.startswith('-')]
    
    logger.info(f"üìä Partitions √† traiter: {len(partitions)}")
    
    # VACUUM FULL chaque partition
    for partition in partitions:
        logger.info(f"   üßπ VACUUM FULL dwh_facts.{partition}...")
        
        vacuum_query = f"VACUUM FULL ANALYZE dwh_facts.{partition};"
        
        try:
            execute_sql(vacuum_query)
            logger.info(f"   ‚úÖ {partition} termin√©")
        except Exception as e:
            logger.warning(f"   ‚ö†Ô∏è  {partition} √©chou√©: {str(e)}")
    
    logger.info("‚úÖ VACUUM FULL termin√©")
    return len(partitions)


@task(name="archive_very_old_partitions", retries=0)
def archive_very_old_partitions():
    """Archiver/supprimer les partitions de plus de 5 ans."""
    logger = get_run_logger()
    logger.info("üì¶ Archivage des tr√®s anciennes partitions...")
    
    # Calculer l'ann√©e limite (5 ans en arri√®re)
    cutoff_year = datetime.now().year - 5
    
    logger.info(f"üìÖ Ann√©e limite: {cutoff_year}")
    
    # Lister les partitions √† archiver
    partitions_query = f"""
    SELECT 
        tablename,
        pg_size_pretty(pg_total_relation_size('dwh_facts.'||tablename)) as size
    FROM pg_tables 
    WHERE schemaname = 'dwh_facts' 
      AND tablename LIKE 'fait_attributions_20%'
      AND tablename < 'fait_attributions_{cutoff_year}'
    ORDER BY tablename;
    """
    
    partitions_output = execute_sql(partitions_query, "Partitions √† archiver")
    
    logger.info(f"Partitions candidates:\n{partitions_output}")
    
    # Pour l'instant, juste logger (ne pas supprimer automatiquement)
    logger.warning("‚ö†Ô∏è  Archivage automatique d√©sactiv√© pour s√©curit√©")
    logger.warning("‚ö†Ô∏è  Ex√©cuter manuellement si n√©cessaire:")
    logger.warning(f"    DROP TABLE dwh_facts.fait_attributions_{cutoff_year-1};")
    
    return 0


@task(name="reindex_tables", retries=0)
def reindex_tables():
    """R√©organiser les index des tables principales."""
    logger = get_run_logger()
    logger.info("üîß R√©organisation des index...")
    
    # Tables de faits principales
    tables = [
        "dwh_facts.fait_attributions",
        "dwh_facts.fait_factures",
        "dwh_facts.fait_collectes",
        "dwh_facts.fait_paiements"
    ]
    
    for table in tables:
        logger.info(f"   üîß REINDEX {table}...")
        
        try:
            reindex_query = f"REINDEX TABLE {table};"
            execute_sql(reindex_query)
            logger.info(f"   ‚úÖ {table} termin√©")
        except Exception as e:
            logger.warning(f"   ‚ö†Ô∏è  {table} √©chou√©: {str(e)}")
    
    logger.info("‚úÖ R√©indexation termin√©e")
    return len(tables)


@task(name="generate_health_report", retries=0)
def generate_health_report():
    """G√©n√©rer un rapport de sant√© de la base."""
    logger = get_run_logger()
    logger.info("üìä G√©n√©ration du rapport de sant√©...")
    
    # Rapport 1: Taille des tables
    size_query = """
    SELECT 
        schemaname || '.' || tablename as table_name,
        pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as total_size,
        pg_size_pretty(pg_relation_size(schemaname||'.'||tablename)) as table_size,
        pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename) - pg_relation_size(schemaname||'.'||tablename)) as index_size
    FROM pg_tables 
    WHERE schemaname IN ('dwh_facts', 'dwh_dim', 'dwh_marts')
    ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
    LIMIT 20;
    """
    
    size_report = execute_sql(size_query, "Taille des tables")
    logger.info(f"\nüìä TOP 20 Tables:\n{size_report}")
    
    # Rapport 2: Nombre de lignes par partition
    rows_query = """
    SELECT 
        tablename,
        (SELECT COUNT(*) FROM dwh_facts.fait_attributions) as estimated_rows
    FROM pg_tables 
    WHERE schemaname = 'dwh_facts' 
      AND tablename LIKE 'fait_attributions_20%'
    LIMIT 5;
    """
    
    rows_report = execute_sql(rows_query, "Lignes par partition")
    logger.info(f"\nüìä Lignes par partition:\n{rows_report}")
    
    # Rapport 3: Index non utilis√©s
    unused_index_query = """
    SELECT 
        schemaname || '.' || tablename as table,
        indexname,
        pg_size_pretty(pg_relation_size(indexrelid)) as index_size
    FROM pg_stat_user_indexes
    WHERE schemaname IN ('dwh_facts', 'dwh_dim', 'dwh_marts')
      AND idx_scan = 0
      AND indexrelname NOT LIKE '%_pkey'
    ORDER BY pg_relation_size(indexrelid) DESC;
    """
    
    unused_report = execute_sql(unused_index_query, "Index non utilis√©s")
    logger.info(f"\nüìä Index non utilis√©s:\n{unused_report}")
    
    # Rapport 4: Bloat estimation
    bloat_query = """
    SELECT 
        schemaname || '.' || tablename as table_name,
        pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size,
        n_dead_tup as dead_tuples,
        ROUND(100.0 * n_dead_tup / NULLIF(n_live_tup + n_dead_tup, 0), 2) as bloat_percent
    FROM pg_stat_user_tables
    WHERE schemaname IN ('dwh_facts', 'dwh_dim', 'dwh_marts')
      AND n_dead_tup > 0
    ORDER BY n_dead_tup DESC
    LIMIT 10;
    """
    
    bloat_report = execute_sql(bloat_query, "Estimation du bloat")
    logger.info(f"\nüìä Tables avec bloat:\n{bloat_report}")
    
    logger.info("‚úÖ Rapport de sant√© g√©n√©r√©")
    return True


@flow(name="SIGETI DWH - Maintenance Mensuelle", log_prints=True)
def sigeti_dwh_monthly_maintenance():
    """
    Flow de maintenance mensuelle pour PRIORIT√â 3.
    
    ‚ö†Ô∏è  √Ä ex√©cuter le 1er de chaque mois √† 3h du matin.
    
    Ce flow:
    1. VACUUM FULL sur anciennes partitions (> 3 mois)
    2. Archive partitions tr√®s anciennes (> 5 ans)
    3. R√©organise les index
    4. G√©n√®re rapport de sant√©
    
    Dur√©e estim√©e: 30-60 minutes
    """
    logger = get_run_logger()
    
    logger.info("=" * 70)
    logger.info("üßπ SIGETI DWH - Maintenance Mensuelle (PRIORIT√â 3)")
    logger.info("=" * 70)
    logger.info(f"‚è∞ D√©but: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("")
    
    try:
        # √âtape 1: VACUUM FULL
        logger.info("[√âTAPE 1/4] VACUUM FULL des anciennes partitions...")
        partitions_vacuumed = vacuum_old_partitions()
        logger.info(f"   ‚úÖ {partitions_vacuumed} partitions trait√©es")
        logger.info("")
        
        # √âtape 2: Archivage
        logger.info("[√âTAPE 2/4] Archivage des tr√®s anciennes partitions...")
        partitions_archived = archive_very_old_partitions()
        logger.info(f"   ‚ÑπÔ∏è  {partitions_archived} partitions archiv√©es")
        logger.info("")
        
        # √âtape 3: R√©indexation
        logger.info("[√âTAPE 3/4] R√©organisation des index...")
        tables_reindexed = reindex_tables()
        logger.info(f"   ‚úÖ {tables_reindexed} tables r√©index√©es")
        logger.info("")
        
        # √âtape 4: Rapport
        logger.info("[√âTAPE 4/4] G√©n√©ration du rapport de sant√©...")
        generate_health_report()
        logger.info("")
        
        logger.info("=" * 70)
        logger.info("‚úÖ Maintenance mensuelle termin√©e avec succ√®s!")
        logger.info("=" * 70)
        logger.info("")
        logger.info("üìä R√©sum√©:")
        logger.info(f"   - Partitions vacuum: {partitions_vacuumed}")
        logger.info(f"   - Partitions archiv√©es: {partitions_archived}")
        logger.info(f"   - Tables r√©index√©es: {tables_reindexed}")
        logger.info("")
        logger.info(f"‚è∞ Fin: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        return "SUCCESS"
        
    except Exception as e:
        logger.error("=" * 70)
        logger.error(f"‚ùå Erreur lors de la maintenance: {str(e)}")
        logger.error("=" * 70)
        raise


if __name__ == "__main__":
    # Ex√©cution locale
    sigeti_dwh_monthly_maintenance()

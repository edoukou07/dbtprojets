# Guide de D√©ploiement - Entrep√¥t de Donn√©es SIGETI

## üìã Table des Mati√®res
1. [√âtat du Projet](#√©tat-du-projet)
2. [Options de D√©ploiement](#options-de-d√©ploiement)
3. [Installation des D√©pendances](#installation-des-d√©pendances)
4. [Configuration](#configuration)
5. [Utilisation](#utilisation)
6. [Monitoring](#monitoring)
7. [Maintenance](#maintenance)
8. [Troubleshooting](#troubleshooting)

---

## ‚úÖ √âtat du Projet

**Statut**: ‚úÖ **PRODUCTION READY**

### R√©sultats de la derni√®re ex√©cution:
- **Staging**: 8/8 mod√®les ‚úÖ (1.44s)
- **Dimensions**: 5/5 tables ‚úÖ (1.27s) - 4,145 lignes
- **Facts**: 4/4 tables ‚úÖ (1.22s)
- **Marts**: 4/4 vues ‚úÖ (1.26s)
- **Tests**: 8/8 validations ‚úÖ (1.06s)
- **Documentation**: G√©n√©r√©e ‚úÖ (3.28s)

**Temps total**: ~9 secondes  
**Taux de succ√®s**: 100%

---

## üöÄ Options de D√©ploiement

### Option 1: Ex√©cution Manuelle (Recommand√© pour d√©buter)

**Avantages**:
- Simple et rapide
- Pas de configuration suppl√©mentaire
- Contr√¥le total sur l'ex√©cution

**Utilisation**:
```powershell
# Ex√©cuter le pipeline
.\run_pipeline.ps1
```

### Option 2: Planification avec Prefect Server (Recommand√© pour production)

**Avantages**:
- Interface web pour monitoring
- Historique des ex√©cutions
- Alertes en cas d'√©chec
- Logs centralis√©s

**Configuration**:
```powershell
# 1. D√©marrer Prefect Server
prefect server start

# 2. Dans un autre terminal, d√©ployer le flow
.\venv\Scripts\Activate.ps1
python prefect\deployments\deploy_scheduled.py

# 3. D√©marrer un agent Prefect
prefect agent start -q default
```

**Acc√®s**: http://localhost:4200 (interface web Prefect)

### Option 3: Planification Windows Task Scheduler (Simple, sans d√©pendances)

**Avantages**:
- Int√©gr√© √† Windows
- Pas de serveur √† maintenir
- D√©marrage automatique

**Configuration**:
```powershell
# Ex√©cuter le script de configuration
.\setup_scheduled_task.ps1

# V√©rifier que la t√¢che est cr√©√©e
Get-ScheduledTask -TaskName "SIGETI_DWH_Daily_Refresh"
```

**Gestion**:
- Ouvrir: `taskschd.msc` (Planificateur de t√¢ches Windows)
- Rechercher: "SIGETI_DWH_Daily_Refresh"
- Historique visible dans l'onglet "Historique"

---

## üì¶ Installation des D√©pendances

### Pr√©requis
- Python 3.12+
- PostgreSQL 13+
- PowerShell 5.1+

### Installation
```powershell
# 1. Cr√©er l'environnement virtuel (d√©j√† fait)
python -m venv venv

# 2. Activer l'environnement
.\venv\Scripts\Activate.ps1

# 3. Installer les packages (d√©j√† fait)
pip install dbt-core==1.10.15 dbt-postgres==1.9.1 prefect==3.6.1 prefect-dbt==0.7.8

# 4. Installer tabulate pour le monitoring
pip install tabulate python-dotenv
```

---

## ‚öôÔ∏è Configuration

### 1. Variables d'Environnement (.env)

Fichier `.env` √† la racine du projet:
```env
# Database Configuration
SOURCE_DB_HOST=localhost
SOURCE_DB_PORT=5432
SOURCE_DB_NAME=sigeti_node_db
SOURCE_DB_USER=postgres
SOURCE_DB_PASSWORD=postgres

DWH_DB_HOST=localhost
DWH_DB_PORT=5432
DWH_DB_NAME=sigeti_node_db
DWH_DB_USER=postgres
DBT_PASSWORD=postgres
```

### 2. Configuration dbt (profiles.yml)

Fichier `C:\Users\hynco\.dbt\profiles.yml`:
```yaml
sigeti_dwh:
  outputs:
    dev:
      type: postgres
      host: localhost
      port: 5432
      user: postgres
      password: postgres
      dbname: sigeti_node_db
      schema: dwh
      threads: 4
      client_encoding: utf8
  target: dev
```

### 3. Configuration Critique

**‚ö†Ô∏è IMPORTANT**: L'encodage UTF-8 est **obligatoire** pour g√©rer les caract√®res fran√ßais.

```powershell
# Le script run_pipeline.ps1 configure automatiquement:
$env:PGCLIENTENCODING = "UTF8"
```

---

## üíª Utilisation

### Ex√©cution Manuelle

```powershell
# Option 1: Script simplifi√© (RECOMMAND√â)
.\run_pipeline.ps1

# Option 2: Commande compl√®te
$env:PGCLIENTENCODING="UTF8"
.\venv\Scripts\Activate.ps1
python prefect\flows\sigeti_dwh_flow.py
```

### Ex√©cution avec dbt uniquement

```powershell
# Activer l'environnement
.\venv\Scripts\Activate.ps1

# Ex√©cuter toutes les transformations
dbt run

# Ex√©cuter une couche sp√©cifique
dbt run --select staging
dbt run --select dimensions
dbt run --select facts
dbt run --select marts

# Ex√©cuter les tests
dbt test

# G√©n√©rer la documentation
dbt docs generate
dbt docs serve  # Ouvre la doc dans le navigateur
```

### Monitoring en Temps R√©el

```powershell
# Afficher le tableau de bord
.\venv\Scripts\Activate.ps1
python monitor_dwh.py
```

---

## üìä Monitoring

### 1. Tableau de Bord Python (monitor_dwh.py)

**Affiche**:
- Nombre de lignes par table/vue
- Taille des objets
- Derni√®res mises √† jour
- Statistiques par couche

**Utilisation**:
```powershell
python monitor_dwh.py
```

### 2. Monitoring via PostgreSQL

```sql
-- Connexion
psql -U postgres -d sigeti_node_db

-- Voir tous les objets du DWH
SELECT 
    schemaname, 
    tablename, 
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
FROM pg_tables
WHERE schemaname LIKE 'dwh%'
ORDER BY schemaname, tablename;

-- Compter les lignes dans les faits
SELECT 'fait_attributions' as table, COUNT(*) FROM dwh_facts.fait_attributions
UNION ALL
SELECT 'fait_collectes', COUNT(*) FROM dwh_facts.fait_collectes
UNION ALL
SELECT 'fait_factures', COUNT(*) FROM dwh_facts.fait_factures
UNION ALL
SELECT 'fait_paiements', COUNT(*) FROM dwh_facts.fait_paiements;

-- V√©rifier la fra√Æcheur des donn√©es
SELECT 
    'fait_attributions' as table,
    MAX(created_at) as derniere_maj
FROM dwh_facts.fait_attributions;
```

### 3. Monitoring via Prefect UI

Si vous utilisez Prefect Server:
1. Ouvrir http://localhost:4200
2. Onglet "Flow Runs" ‚Üí voir l'historique
3. Cliquer sur un run ‚Üí voir les logs d√©taill√©s
4. Onglet "Deployments" ‚Üí voir les planifications

---

## üîß Maintenance

### Rafra√Æchissement des Donn√©es

**Fr√©quence recommand√©e**: Quotidienne (2:00 AM)

**Mode incr√©mental**: Les tables de faits (`fait_*`) utilisent une strat√©gie incr√©mentale:
- Premi√®re ex√©cution: charge toutes les donn√©es
- Ex√©cutions suivantes: charge uniquement les nouvelles/modifi√©es

**Rafra√Æchissement complet** (si n√©cessaire):
```powershell
# Option 1: Via dbt
dbt run --full-refresh

# Option 2: Supprimer et recr√©er
psql -U postgres -d sigeti_node_db -c "DROP SCHEMA dwh CASCADE; CREATE SCHEMA dwh;"
.\run_pipeline.ps1
```

### Nettoyage

```powershell
# Supprimer les fichiers compil√©s dbt
Remove-Item -Recurse -Force target, dbt_packages, logs

# Reconstruire les packages dbt
dbt deps
```

### Mise √† Jour des Mod√®les

1. Modifier les fichiers `.sql` dans `models/`
2. Tester localement:
   ```powershell
   dbt run --select <nom_du_modele>
   dbt test --select <nom_du_modele>
   ```
3. Ex√©cuter le pipeline complet pour validation

---

## üêõ Troubleshooting

### Probl√®me: Erreur UTF-8 / Caract√®res fran√ßais

**Sympt√¥me**: `UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9`

**Solution**:
```powershell
# Utiliser le script run_pipeline.ps1 qui configure automatiquement UTF-8
.\run_pipeline.ps1

# Ou d√©finir manuellement
$env:PGCLIENTENCODING="UTF8"
```

### Probl√®me: Connexion PostgreSQL refus√©e

**Sympt√¥me**: `could not connect to server: Connection refused`

**Solution**:
```powershell
# V√©rifier que PostgreSQL est d√©marr√©
Get-Service -Name postgresql*

# D√©marrer si n√©cessaire
Start-Service postgresql-x64-13  # Adapter selon votre version

# Tester la connexion
psql -U postgres -d sigeti_node_db -c "SELECT 1;"
```

### Probl√®me: Colonne n'existe pas

**Sympt√¥me**: `ERROR: column "xxx" does not exist`

**Solution**:
1. V√©rifier le sch√©ma source:
   ```sql
   SELECT column_name, data_type 
   FROM information_schema.columns 
   WHERE table_name = 'nom_table' AND table_schema = 'public';
   ```
2. Mettre √† jour le mod√®le dbt correspondant
3. Re-ex√©cuter le pipeline

### Probl√®me: Tests dbt √©chouent

**Sympt√¥me**: `FAIL` dans les tests

**Solution**:
```powershell
# Voir les d√©tails des √©checs
dbt test --select <test_name> --store-failures

# V√©rifier les donn√©es probl√©matiques
psql -U postgres -d sigeti_node_db
SELECT * FROM dwh.dbt_test__audit LIMIT 10;
```

### Probl√®me: Prefect ne trouve pas le flow

**Sympt√¥me**: `Flow not found`

**Solution**:
```powershell
# Re-d√©ployer le flow
python prefect\deployments\deploy_scheduled.py

# V√©rifier les d√©ploiements
prefect deployment ls
```

---

## üìö Ressources

### Documentation
- **dbt**: https://docs.getdbt.com/
- **Prefect**: https://docs.prefect.io/
- **PostgreSQL**: https://www.postgresql.org/docs/

### Fichiers Cl√©s
```
DWH_SIG/
‚îú‚îÄ‚îÄ run_pipeline.ps1           # Script d'ex√©cution principal
‚îú‚îÄ‚îÄ monitor_dwh.py             # Tableau de bord monitoring
‚îú‚îÄ‚îÄ setup_scheduled_task.ps1   # Configuration Windows Task
‚îú‚îÄ‚îÄ prefect/
‚îÇ   ‚îú‚îÄ‚îÄ flows/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sigeti_dwh_flow.py    # Orchestration Prefect
‚îÇ   ‚îî‚îÄ‚îÄ deployments/
‚îÇ       ‚îî‚îÄ‚îÄ deploy_scheduled.py   # D√©ploiement avec schedule
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ staging/               # 8 vues de staging
‚îÇ   ‚îú‚îÄ‚îÄ dimensions/            # 5 tables de dimensions
‚îÇ   ‚îú‚îÄ‚îÄ facts/                 # 4 tables de faits
‚îÇ   ‚îî‚îÄ‚îÄ marts/                 # 4 vues analytiques
‚îú‚îÄ‚îÄ .env                       # Configuration
‚îî‚îÄ‚îÄ profiles.yml              # Configuration dbt (dans ~/.dbt/)
```

### Support
- Pour les questions: Consulter les logs dans `logs/dbt.log`
- Pour les erreurs Prefect: Voir l'UI Prefect ou les logs terminal
- Pour PostgreSQL: Consulter les logs dans le r√©pertoire `pg_log/`

---

## üéØ Prochaines √âtapes Recommand√©es

1. **Court terme**:
   - ‚úÖ Choisir une option de planification (Prefect ou Task Scheduler)
   - ‚úÖ Configurer le monitoring automatique
   - ‚úÖ Tester le rafra√Æchissement incr√©mental

2. **Moyen terme**:
   - üìä Connecter un outil de BI (Power BI, Tableau, Metabase)
   - üìß Configurer des alertes email en cas d'√©chec
   - üîÑ Ajouter des snapshots dbt pour l'historisation

3. **Long terme**:
   - ‚òÅÔ∏è Migrer vers Azure/AWS pour la production
   - üîê Impl√©menter la s√©curit√© au niveau des lignes
   - üìà Optimiser les performances (index, partitionnement)

---

**Version**: 1.0  
**Date**: 2025-01-13  
**Statut**: Production Ready ‚úÖ
